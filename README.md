# Prueba de Desempe√±o üñ•Ô∏è Modelado de Datos


### Prueba de Desempe√±o 3 - Implementaci√≥n de Dataset con noSQL <br>
### Equipo _02_: 
* Alberto Enrique Baeza Vivas ü¶ß
* Luis Manuel Palma Pinto ü¶ñ
* Diego Gaytan Bola√±os üê≥

1. Identificar un	dataset	de	kaggle	(https://www.kaggle.com/datasets)	que	pueda	ser	modelado	con	su	BD	NoSQL (que	no	se	haya	utilizado	durante	el	curso). üîç
2. Haciendo	uso	de	un	repositorio	de	Github,	documente	lo	siguiente: üìù
   * **a.** Agregar el	archivo	del	dataset
<br> > El archivo del dataset se llama "_albums.csv_", al estar en formato **csv** para que este funcione utilizamos un programa que hicimos en **python** para convertirlo a formato **JSON** y que funcionara en el **CouchDB**, este programa se llama "_convertidor.py_", m√°s informaci√≥n en su punto respectivo.
   * **b.** Descripci√≥n	del	dataset
<br> > El dataset muestra el top 500 de los albumes mejor valorados, de acuerdo con la revista Rolling Stone, este dataset muestra el puesto, nombre, a√±o, artista, genero y subgenero de cada album en la lista.
   * **c.** Descripci√≥n	del	diccionario	de	datos	del	dataset
   * **d.** Descripci√≥n	del	modelado	del	dataset	seg√∫n	la	BD	NoSQL
  <br> > Nuestra base de datos tiene documentos en los que almacena una representaci√≥n de un √°lbum de m√∫sica. Esta representaci√≥n viene a estar dada por documentos **JSON** los cuales son representativos a un modelo **Clave-Valor**. Por otro lado, cada uno de estos documentos almacena la siguiente informaci√≥n: Number, Year, Album, Artist, Genre, y Sugenre.
   * **e.** Descripci√≥n	de	la	BD	NoSQL	y	las	herramientas	que	se	utilizaron.
   <br> > La base de datos utilizada es **CouchDB** la cual es una base de datos orientada a documentos, que se comunica a trav√©s de ua API HTTP y almacena datos en formato **JSON**.
<br> Por otro lado, se utilizaron herramientas externas como **Python** junto con la instalaci√≥n de algunas librer√≠as tales como **Pandas**, **CouchDB**, **JSON**, **Chardet** las cuales fueron utiles para realizar la importaci√≥n del dataset. Todo este proceso fue realizado utilizando **VSCode**. Tambien se utilizo la interfaz web **Fauxton** para poder crear la DB y poder visualizar los datos.
<br> **Nota:** Se utilizo esta base de datos en lugar de DynamoDB debido a que hab√≠a que pagar por su uso.

   * **f.** Descripci√≥n	de	la	importaci√≥n	de	sus	datos.
##### Antes de importar 
<br> > Antes de realizar la importaci√≥n de los datos primero se tuvo que haber creado la BD, nosotros realizamos este paso de manera manual directo desde el cliente de CouchDB. Para ello, con el CouchDB instalado nos dirigimos a nuestro navegador y utilizamos la siguiente liga: [local](http://localhost:5984/_utils/#login)
<br> Posteriormente de haber ingresado nuestro usuario y contrase√±a, simplemente le damos clic a la parte superior derecha del cliente donde dice 'Create Database' 
<br> ![image](https://github.com/DGSENZEN/ProyectoDatos/assets/148842609/3d77a5dd-e6fc-427f-86ba-9dab3f3bd6d4)
<br> En nuestro caso, decidimos utilizar el nombre de 'albums' y creamos. 
<br> ![image](https://github.com/DGSENZEN/ProyectoDatos/assets/148842609/526dd51f-fa3a-43a3-9480-9205f7a4dc16)
<br>Nos daremos cuenta que fue creada con √©xito si aparece as√≠:
![image](https://github.com/DGSENZEN/ProyectoDatos/assets/148842609/8268a9f8-7498-4dcd-9286-01dfb80c0e60)
##### Ahora, s√≠. Para importar
<br> > Para la importaci√≥n del dataset se tuvo que realizar una modificaci√≥n de la extensi√≥n .csv a .json, esto se debe a que CouchDB solo reconoce este tipo de extensi√≥n. En este cambio se utilizo un script en python llamado **'convertidor.py'**, el cual identifica el tipo de la codificaci√≥n que tiene el csv para posteriormente hacer la conversion a json.
<br> > Luego, ya con la extensi√≥n correcta se utilizo el script **'subirDataSet.py'**, con ese documento se sube el dataset a la BD, utilizando como recurso la API que tiene CouchDB. Podemos darnos cuenta que efectivamete si se realizo bien la importaci√≥n ya que contiene los 500 elementos que esperabamos. 
<br>
<br> **Nota** : Dentro de cada uno de los scripts hay una descripci√≥n m√°s detallada de c√≥mo funciona.
<br>
![image](https://github.com/DGSENZEN/ProyectoDatos/assets/148842609/398f48e6-55b2-4864-8e2f-4276ae6aba53)
<br>
<br>Veamos una parte de los datos que se importaron
<br>![image](https://github.com/DGSENZEN/ProyectoDatos/assets/148842609/3a387cbd-d786-42e7-be9e-da8605696179)

   * **g.** Definir	 y	 describir	 al	 menos	 5	 sentencias	 para	 cada	 una	 de	 las operaciones	CRUD (Create,	Read,	Update,	Delete) en	la	BD.

<br> En CouchDB las operaciones CRUD se realizan usando metodos **HTTP** en los documentos de la base de datos. 
<br> > **Create** (Aqui se conocen como "POST")
<br> >> Crear un nuevo documento con datos especificos: curl -X POST http://localhost:5984/tu_basededatos -d '{"number": 501, "year": 2010, "album": "Razor", "artist": "The Colds", "genre:" "Rock", "subgenre:" "Pop rock"}'
<br> >> Agregar un nuevo documento con atributos unicos: curl -X POST http://localhost:5984/tu_basededatos -d '{"titulo": "Rock y m√°s", "contenido": "Descubre la historia del rock."}'
<br> >> Agregar un nuevo documento con atributos unicos: curl -X POST http://localhost:5984/tu_basededatos -d '{"titulo": "Rock y m√°s", "contenido": "Descubre la historia del rock."}'
<br> > **Read**
<br> > **Update**
<br> > **Delete**
<br> 3. El	 github deber√°	 estar	 organizado	 de	 tal	 manera	 que	 sea	 f√°cil	 navegar	 o identificar	los	puntos	antes	mencionados. üß≠
<br> 4. En	la	plataforma	Moodle	subir	la	URL	del	repositorio. ‚¨ÜÔ∏è
<br> 5. Deber√°n	presentar	el	trabajo	realizado	a	sus	compa√±eros	en	el	sal√≥n	de	clases	(verificar	tabla	de cotejo). üé•
